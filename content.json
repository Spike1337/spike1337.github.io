{"meta":{"title":"Spike World","subtitle":"","description":"","author":"Spike1337","url":"https://spike1337.github.io","root":"/"},"pages":[{"title":"书单","date":"2023-08-22T01:36:55.577Z","updated":"2023-08-22T01:36:55.577Z","comments":false,"path":"books/index.html","permalink":"https://spike1337.github.io/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-08-22T01:36:55.579Z","updated":"2023-08-22T01:36:55.579Z","comments":false,"path":"repository/index.html","permalink":"https://spike1337.github.io/repository/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2023-08-22T01:36:55.578Z","updated":"2023-08-22T01:36:55.578Z","comments":true,"path":"links/index.html","permalink":"https://spike1337.github.io/links/index.html","excerpt":"","text":""},{"title":"关于","date":"2023-08-22T07:12:37.136Z","updated":"2023-08-22T07:12:37.136Z","comments":false,"path":"about/index.html","permalink":"https://spike1337.github.io/about/index.html","excerpt":"","text":"Hi there 👋, I am Spike I am a… 🏃 Database kernal Developer Skills 🚀 Language: C/C++, Python, Shell, SQL, rust 🔥 Backend: PostgreSQL, GreenPlum Current Develop direction 😇 Storage &amp; Transaction Others… 💖 Anime: Space Cowboy 💖 Movie: Interstellar 💖 Games: FPS さいこう!"},{"title":"分类","date":"2023-08-22T01:36:55.577Z","updated":"2023-08-22T01:36:55.577Z","comments":false,"path":"categories/index.html","permalink":"https://spike1337.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-08-22T01:36:55.581Z","updated":"2023-08-22T01:36:55.581Z","comments":false,"path":"tags/index.html","permalink":"https://spike1337.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2023-08-22T10:07:12.797Z","updated":"2023-08-22T10:07:12.797Z","comments":true,"path":"self/one-light.css","permalink":"https://spike1337.github.io/self/one-light.css","excerpt":"","text":"/** * One Light theme for prism.js * Based on Atom's One Light theme: https://github.com/atom/atom/tree/master/packages/one-light-syntax */ /** * One Light colours (accurate as of commit eb064bf on 19 Feb 2021) * From colors.less * --mono-1: hsl(230, 8%, 24%); * --mono-2: hsl(230, 6%, 44%); * --mono-3: hsl(230, 4%, 64%) * --hue-1: hsl(198, 99%, 37%); * --hue-2: hsl(221, 87%, 60%); * --hue-3: hsl(301, 63%, 40%); * --hue-4: hsl(119, 34%, 47%); * --hue-5: hsl(5, 74%, 59%); * --hue-5-2: hsl(344, 84%, 43%); * --hue-6: hsl(35, 99%, 36%); * --hue-6-2: hsl(35, 99%, 40%); * --syntax-fg: hsl(230, 8%, 24%); * --syntax-bg: hsl(230, 1%, 98%); * --syntax-gutter: hsl(230, 1%, 62%); * --syntax-guide: hsla(230, 8%, 24%, 0.2); * --syntax-accent: hsl(230, 100%, 66%); * From syntax-variables.less * --syntax-selection-color: hsl(230, 1%, 90%); * --syntax-gutter-background-color-selected: hsl(230, 1%, 90%); * --syntax-cursor-line: hsla(230, 8%, 24%, 0.05); */ code[class*=\"language-\"], pre[class*=\"language-\"] { background: hsl(230, 1%, 98%); color: hsl(230, 8%, 24%); font-family: \"Fira Code\", \"Fira Mono\", Menlo, Consolas, \"DejaVu Sans Mono\", monospace; direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; line-height: 1.5; -moz-tab-size: 2; -o-tab-size: 2; tab-size: 2; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Selection */ code[class*=\"language-\"]::-moz-selection, code[class*=\"language-\"] *::-moz-selection, pre[class*=\"language-\"] *::-moz-selection { background: hsl(230, 1%, 90%); color: inherit; } code[class*=\"language-\"]::selection, code[class*=\"language-\"] *::selection, pre[class*=\"language-\"] *::selection { background: hsl(230, 1%, 90%); color: inherit; } /* Code blocks */ pre[class*=\"language-\"] { padding: 1em; margin: 0.5em 0; overflow: auto; border-radius: 0.3em; } /* Inline code */ :not(pre) > code[class*=\"language-\"] { padding: 0.2em 0.3em; border-radius: 0.3em; white-space: normal; } .token.comment, .token.prolog, .token.cdata { color: hsl(230, 4%, 64%); } .token.doctype, .token.punctuation, .token.entity { color: hsl(230, 8%, 24%); } .token.attr-name, .token.class-name, .token.boolean, .token.constant, .token.number, .token.atrule { color: hsl(35, 99%, 36%); } .token.keyword { color: hsl(301, 63%, 40%); } .token.property, .token.tag, .token.symbol, .token.deleted, .token.important { color: hsl(5, 74%, 59%); } .token.selector, .token.string, .token.char, .token.builtin, .token.inserted, .token.regex, .token.attr-value, .token.attr-value > .token.punctuation { color: hsl(119, 34%, 47%); } .token.variable, .token.operator, .token.function { color: hsl(221, 87%, 60%); } .token.url { color: hsl(198, 99%, 37%); } /* HTML overrides */ .token.attr-value > .token.punctuation.attr-equals, .token.special-attr > .token.attr-value > .token.value.css { color: hsl(230, 8%, 24%); } /* CSS overrides */ .language-css .token.selector { color: hsl(5, 74%, 59%); } .language-css .token.property { color: hsl(230, 8%, 24%); } .language-css .token.function, .language-css .token.url > .token.function { color: hsl(198, 99%, 37%); } .language-css .token.url > .token.string.url { color: hsl(119, 34%, 47%); } .language-css .token.important, .language-css .token.atrule .token.rule { color: hsl(301, 63%, 40%); } /* JS overrides */ .language-javascript .token.operator { color: hsl(301, 63%, 40%); } .language-javascript .token.template-string > .token.interpolation > .token.interpolation-punctuation.punctuation { color: hsl(344, 84%, 43%); } /* JSON overrides */ .language-json .token.operator { color: hsl(230, 8%, 24%); } .language-json .token.null.keyword { color: hsl(35, 99%, 36%); } /* MD overrides */ .language-markdown .token.url, .language-markdown .token.url > .token.operator, .language-markdown .token.url-reference.url > .token.string { color: hsl(230, 8%, 24%); } .language-markdown .token.url > .token.content { color: hsl(221, 87%, 60%); } .language-markdown .token.url > .token.url, .language-markdown .token.url-reference.url { color: hsl(198, 99%, 37%); } .language-markdown .token.blockquote.punctuation, .language-markdown .token.hr.punctuation { color: hsl(230, 4%, 64%); font-style: italic; } .language-markdown .token.code-snippet { color: hsl(119, 34%, 47%); } .language-markdown .token.bold .token.content { color: hsl(35, 99%, 36%); } .language-markdown .token.italic .token.content { color: hsl(301, 63%, 40%); } .language-markdown .token.strike .token.content, .language-markdown .token.strike .token.punctuation, .language-markdown .token.list.punctuation, .language-markdown .token.title.important > .token.punctuation { color: hsl(5, 74%, 59%); } /* General */ .token.bold { font-weight: bold; } .token.comment, .token.italic { font-style: italic; } .token.entity { cursor: help; } .token.namespace { opacity: 0.8; } /* Plugin overrides */ /* Selectors should have higher specificity than those in the plugins' default stylesheets */ /* Show Invisibles plugin overrides */ .token.token.tab:not(:empty):before, .token.token.cr:before, .token.token.lf:before, .token.token.space:before { color: hsla(230, 8%, 24%, 0.2); } /* Toolbar plugin overrides */ /* Space out all buttons and move them away from the right edge of the code block */ div.code-toolbar > .toolbar.toolbar > .toolbar-item { margin-right: 0.4em; } /* Styling the buttons */ div.code-toolbar > .toolbar.toolbar > .toolbar-item > button, div.code-toolbar > .toolbar.toolbar > .toolbar-item > a, div.code-toolbar > .toolbar.toolbar > .toolbar-item > span { background: hsl(230, 1%, 90%); color: hsl(230, 6%, 44%); padding: 0.1em 0.4em; border-radius: 0.3em; } div.code-toolbar > .toolbar.toolbar > .toolbar-item > button:hover, div.code-toolbar > .toolbar.toolbar > .toolbar-item > button:focus, div.code-toolbar > .toolbar.toolbar > .toolbar-item > a:hover, div.code-toolbar > .toolbar.toolbar > .toolbar-item > a:focus, div.code-toolbar > .toolbar.toolbar > .toolbar-item > span:hover, div.code-toolbar > .toolbar.toolbar > .toolbar-item > span:focus { background: hsl(230, 1%, 78%); /* custom: darken(--syntax-bg, 20%) */ color: hsl(230, 8%, 24%); } /* Line Highlight plugin overrides */ /* The highlighted line itself */ .line-highlight.line-highlight { background: hsla(230, 8%, 24%, 0.05); } /* Default line numbers in Line Highlight plugin */ .line-highlight.line-highlight:before, .line-highlight.line-highlight[data-end]:after { background: hsl(230, 1%, 90%); color: hsl(230, 8%, 24%); padding: 0.1em 0.6em; border-radius: 0.3em; box-shadow: 0 2px 0 0 rgba(0, 0, 0, 0.2); /* same as Toolbar plugin default */ } /* Hovering over a linkable line number (in the gutter area) */ /* Requires Line Numbers plugin as well */ pre[id].linkable-line-numbers.linkable-line-numbers span.line-numbers-rows > span:hover:before { background-color: hsla(230, 8%, 24%, 0.05); } /* Line Numbers and Command Line plugins overrides */ /* Line separating gutter from coding area */ .line-numbers.line-numbers .line-numbers-rows, .command-line .command-line-prompt { border-right-color: hsla(230, 8%, 24%, 0.2); } /* Stuff in the gutter */ .line-numbers .line-numbers-rows > span:before, .command-line .command-line-prompt > span:before { color: hsl(230, 1%, 62%); } /* Match Braces plugin overrides */ /* Note: Outline colour is inherited from the braces */ .rainbow-braces .token.token.punctuation.brace-level-1, .rainbow-braces .token.token.punctuation.brace-level-5, .rainbow-braces .token.token.punctuation.brace-level-9 { color: hsl(5, 74%, 59%); } .rainbow-braces .token.token.punctuation.brace-level-2, .rainbow-braces .token.token.punctuation.brace-level-6, .rainbow-braces .token.token.punctuation.brace-level-10 { color: hsl(119, 34%, 47%); } .rainbow-braces .token.token.punctuation.brace-level-3, .rainbow-braces .token.token.punctuation.brace-level-7, .rainbow-braces .token.token.punctuation.brace-level-11 { color: hsl(221, 87%, 60%); } .rainbow-braces .token.token.punctuation.brace-level-4, .rainbow-braces .token.token.punctuation.brace-level-8, .rainbow-braces .token.token.punctuation.brace-level-12 { color: hsl(301, 63%, 40%); } /* Diff Highlight plugin overrides */ /* Taken from https://github.com/atom/github/blob/master/styles/variables.less */ pre.diff-highlight > code .token.token.deleted:not(.prefix), pre > code.diff-highlight .token.token.deleted:not(.prefix) { background-color: hsla(353, 100%, 66%, 0.15); } pre.diff-highlight > code .token.token.deleted:not(.prefix)::-moz-selection, pre.diff-highlight > code .token.token.deleted:not(.prefix) *::-moz-selection, pre > code.diff-highlight .token.token.deleted:not(.prefix)::-moz-selection, pre > code.diff-highlight .token.token.deleted:not(.prefix) *::-moz-selection { background-color: hsla(353, 95%, 66%, 0.25); } pre.diff-highlight > code .token.token.deleted:not(.prefix)::selection, pre.diff-highlight > code .token.token.deleted:not(.prefix) *::selection, pre > code.diff-highlight .token.token.deleted:not(.prefix)::selection, pre > code.diff-highlight .token.token.deleted:not(.prefix) *::selection { background-color: hsla(353, 95%, 66%, 0.25); } pre.diff-highlight > code .token.token.inserted:not(.prefix), pre > code.diff-highlight .token.token.inserted:not(.prefix) { background-color: hsla(137, 100%, 55%, 0.15); } pre.diff-highlight > code .token.token.inserted:not(.prefix)::-moz-selection, pre.diff-highlight > code .token.token.inserted:not(.prefix) *::-moz-selection, pre > code.diff-highlight .token.token.inserted:not(.prefix)::-moz-selection, pre > code.diff-highlight .token.token.inserted:not(.prefix) *::-moz-selection { background-color: hsla(135, 73%, 55%, 0.25); } pre.diff-highlight > code .token.token.inserted:not(.prefix)::selection, pre.diff-highlight > code .token.token.inserted:not(.prefix) *::selection, pre > code.diff-highlight .token.token.inserted:not(.prefix)::selection, pre > code.diff-highlight .token.token.inserted:not(.prefix) *::selection { background-color: hsla(135, 73%, 55%, 0.25); } /* Previewers plugin overrides */ /* Based on https://github.com/atom-community/atom-ide-datatip/blob/master/styles/atom-ide-datatips.less and https://github.com/atom/atom/blob/master/packages/one-light-ui */ /* Border around popup */ .prism-previewer.prism-previewer:before, .prism-previewer-gradient.prism-previewer-gradient div { border-color: hsl(0, 0, 95%); } /* Angle and time should remain as circles and are hence not included */ .prism-previewer-color.prism-previewer-color:before, .prism-previewer-gradient.prism-previewer-gradient div, .prism-previewer-easing.prism-previewer-easing:before { border-radius: 0.3em; } /* Triangles pointing to the code */ .prism-previewer.prism-previewer:after { border-top-color: hsl(0, 0, 95%); } .prism-previewer-flipped.prism-previewer-flipped.after { border-bottom-color: hsl(0, 0, 95%); } /* Background colour within the popup */ .prism-previewer-angle.prism-previewer-angle:before, .prism-previewer-time.prism-previewer-time:before, .prism-previewer-easing.prism-previewer-easing { background: hsl(0, 0%, 100%); } /* For angle, this is the positive area (eg. 90deg will display one quadrant in this colour) */ /* For time, this is the alternate colour */ .prism-previewer-angle.prism-previewer-angle circle, .prism-previewer-time.prism-previewer-time circle { stroke: hsl(230, 8%, 24%); stroke-opacity: 1; } /* Stroke colours of the handle, direction point, and vector itself */ .prism-previewer-easing.prism-previewer-easing circle, .prism-previewer-easing.prism-previewer-easing path, .prism-previewer-easing.prism-previewer-easing line { stroke: hsl(230, 8%, 24%); } /* Fill colour of the handle */ .prism-previewer-easing.prism-previewer-easing circle { fill: transparent; }"},{"title":"404 Not Found：该页无法显示","date":"2023-08-22T01:36:55.568Z","updated":"2023-08-22T01:36:55.568Z","comments":false,"path":"/404.html","permalink":"https://spike1337.github.io/404.html","excerpt":"","text":""}],"posts":[{"title":"Butterfly主题Markdown样式测试","slug":"butterfly-test","date":"2023-08-22T06:37:00.000Z","updated":"2023-08-24T01:24:06.741Z","comments":true,"path":"2023/08/22/butterfly-test/","link":"","permalink":"https://spike1337.github.io/2023/08/22/butterfly-test/","excerpt":"","text":"H1标题 这是一些文字样式。 Here are some text styles. H2标题 H3标题 H4标题 斜体 粗体 代码 行内代码 rm -rf /root/ 代码高亮 123456789class foo&#123;private: int id; std::string text;public: void print_text(void);&#125;; 1234567def fib(n): a, b = 0, 1 while a &lt; n: print(a, end=&#x27; &#x27;) a, b = b, a+b print()fib(1000) 表格 key value comment key1 value1 comment1 key2 value2 comment2 key3 value3 comment3 列表 有序列表 comment1 comment2 comment3 无序列表 function1 function2 function3 function4 图片 勾选框 todo 1 todo 2 emoji 😢 这是个很重要的功能！ 便签 提示 这是一个提示 注意 这是一个警告 警告 这是一个危险信号 成功 这是一个成功信号","categories":[{"name":"demo","slug":"demo","permalink":"https://spike1337.github.io/categories/demo/"}],"tags":[{"name":"demo","slug":"demo","permalink":"https://spike1337.github.io/tags/demo/"}]},{"title":"C标准库 · 文件访问 · statx","slug":"statx","date":"2023-07-25T06:41:21.000Z","updated":"2023-08-22T01:36:55.571Z","comments":true,"path":"2023/07/25/statx/","link":"","permalink":"https://spike1337.github.io/2023/07/25/statx/","excerpt":"","text":"最近开发遇到一个问题，想要获取某个文件毫秒级的修改时间。众所周知C标准库中提供的stat函数只能获取到秒级的修改时间st_mtime。相关的信息翻了个遍，最终还是神奇的ChatGPT给我了答案： Linux 4.11及更高版本，支持statx提供了毫秒级的文件修改时间 SYNOPSIS STRUCT 1234567891011121314151617181920212223242526272829303132333435363738struct statx &#123; __u32 stx_mask; /* Mask of bits indicating filled fields */ __u32 stx_blksize; /* Block size for filesystem I/O */ __u64 stx_attributes; /* Extra file attribute indicators */ __u32 stx_nlink; /* Number of hard links */ __u32 stx_uid; /* User ID of owner */ __u32 stx_gid; /* Group ID of owner */ __u16 stx_mode; /* File type and mode */ __u64 stx_ino; /* Inode number */ __u64 stx_size; /* Total size in bytes */ __u64 stx_blocks; /* Number of 512B blocks allocated */ __u64 stx_attributes_mask; /* Mask to show what&#x27;s supported in stx_attributes */ /* The following fields are file timestamps */ struct statx_timestamp stx_atime; /* Last access */ struct statx_timestamp stx_btime; /* Creation */ struct statx_timestamp stx_ctime; /* Last status change */ struct statx_timestamp stx_mtime; /* Last modification */ /* If this file represents a device, then the next two fields contain the ID of the device */ __u32 stx_rdev_major; /* Major ID */ __u32 stx_rdev_minor; /* Minor ID */ /* The next two fields contain the ID of the device containing the filesystem where the file resides */ __u32 stx_dev_major; /* Major ID */ __u32 stx_dev_minor; /* Minor ID */ __u64 stx_mnt_id; /* Mount ID */ /* Direct I/O alignment restrictions */ __u32 stx_dio_mem_align; __u32 stx_dio_offset_align;&#125;; 其中四个statx_timestamp就是我们需要的毫秒级时间戳 12345struct statx_timestamp &#123; __s64 tv_sec; // 秒数时间戳 __u32 tv_nsec; // tv_srchi周的纳秒数 __s32 __reserved; // 保留精度&#125;; FUNCTION 函数statx位于C标准库 Standard C library (libc, -lc)，函数的声明和使用如下 123456#define _GNU_SOURCE#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;int statx(int dirfd, const char *restrict pathname, int flags, unsigned int mask, struct statx *restrict statxbuf); RETURN 如果执行成功，返回0，否则返回-1并设置errno 更详细的信息请移步 LINUX MANUAL PAGE Example 我自己测试的一个简单例子 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;error.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdint.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;sys/stat.h&gt;#include &lt;time.h&gt;#include &lt;unistd.h&gt;int main() &#123; const char *filename = &quot;tmp_file&quot;; // statx 结构体 struct statx buffer; // AT_FDCWD 在当前目录下运行 // STATX_MTIME 获取修改时间 // AT_SYMLINK_NOFOLLOW 如果是链接则返回链接本身信息 int result = statx(AT_FDCWD, filename, AT_SYMLINK_NOFOLLOW, STATX_MTIME, &amp;buffer); if (result == -1) &#123; fprintf(stderr, &quot;Error: %m\\n&quot;); return 1; &#125; // buffer.stx_mtime 记录文件的最后修改时间 // tv_sec 是秒级, tv_nsec 是毫秒级 int64_t sec = buffer.stx_mtime.tv_sec; int micro_sec = buffer.stx_mtime.tv_nsec / 1000; char time_str[128]; strftime(time_str, 128, &quot;%Y-%m-%d %H:%M:%S&quot;, localtime(&amp;sec)); fprintf(stdout, &quot;Modification time of file %s is %s.%d\\n&quot;, filename, time_str, micro_sec); return 0;&#125; Linux测试用例 https://kgithub.com/torvalds/linux/blob/master/samples/vfs/test-statx.c","categories":[{"name":"Linux","slug":"Linux","permalink":"https://spike1337.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://spike1337.github.io/tags/Linux/"},{"name":"libc","slug":"libc","permalink":"https://spike1337.github.io/tags/libc/"},{"name":"file access","slug":"file-access","permalink":"https://spike1337.github.io/tags/file-access/"}]},{"title":"PostgreSQL源码 · 元组管理（三）· 元组的插入","slug":"tuple_insert","date":"2023-07-13T11:02:08.000Z","updated":"2023-08-24T01:54:58.113Z","comments":true,"path":"2023/07/13/tuple_insert/","link":"","permalink":"https://spike1337.github.io/2023/07/13/tuple_insert/","excerpt":"","text":"元组插入 元组的插入主要由函数heap_insert来完成，主要分为几步： 初始化元组头 HeapTupleHeader 获取可用的page 判断元组可见性和事务冲突 将元组写入可用的page，并标记page dirty 写wal 初始化元组的元数据 在heap_prepare_insert中完成，接口比较简单，我们直接来看源码 123456789101112131415161718192021222324252627282930313233static HeapTupleheap_prepare_insert(Relation relation, HeapTuple tup, TransactionId xid, CommandId cid, int options)&#123; /* 计算元组的infomask &amp; infomask2 */ tup-&gt;t_data-&gt;t_infomask &amp;= ~(HEAP_XACT_MASK); tup-&gt;t_data-&gt;t_infomask2 &amp;= ~(HEAP2_XACT_MASK); tup-&gt;t_data-&gt;t_infomask |= HEAP_XMAX_INVALID; /* 设置xmin，也就是元组插入的事务号 */ HeapTupleHeaderSetXmin(tup-&gt;t_data, xid); if (options &amp; HEAP_INSERT_FROZEN) HeapTupleHeaderSetXminFrozen(tup-&gt;t_data); /* 设置cid、xmax和tableoid，由于是元组插入，则将xmax设置为0 */ HeapTupleHeaderSetCmin(tup-&gt;t_data, cid); HeapTupleHeaderSetXmax(tup-&gt;t_data, 0); tup-&gt;t_tableOid = RelationGetRelid(relation); /* 判断是否为TOAST元组 */ if (relation-&gt;rd_rel-&gt;relkind != RELKIND_RELATION &amp;&amp; relation-&gt;rd_rel-&gt;relkind != RELKIND_MATVIEW) &#123; Assert(!HeapTupleHasExternal(tup)); return tup; &#125; else if (HeapTupleHasExternal(tup) || tup-&gt;t_len &gt; TOAST_TUPLE_THRESHOLD) /* TOAST元组，调用相应的插入接口 */ return heap_toast_insert_or_update(relation, tup, NULL, options); else /* 否则直接返回准备好的tup */ return tup;&#125; 获取可用的page 在RelationGetBufferForTuple中完成。 relation是目标表对象，len是tuple插入需要的长度。otherBuffer用于元组update时替换旧的buffer，options是写入的选项，bistate表示批量插入对象的状态，vmbuffer和vmbuffer_other用于可见性映射 12345BufferRelationGetBufferForTuple(Relation relation, Size len, Buffer otherBuffer, int options, BulkInsertState bistate, Buffer *vmbuffer, Buffer *vmbuffer_other) 通过填充因子，计算空闲空间。 填充因子FillFactor是一个百分比，限制了我们对于page的使用率 1234567891011// 这里使用了默认填充百分比, HEAP_DEFAULT_FILLFACTOR = 100, 也就是完全填充saveFreeSpace = RelationGetTargetPageFreeSpace(relation, HEAP_DEFAULT_FILLFACTOR);// 没有tuple的page中也可能有line pointer，所以使用一个近似值nearlyEmptyFreeSpace = MaxHeapTupleSize - (MaxHeapTuplesPerPage / 8 * sizeof(ItemIdData));if (len + saveFreeSpace &gt; nearlyEmptyFreeSpace) targetFreeSpace = Max(len, nearlyEmptyFreeSpace);else targetFreeSpace = len + saveFreeSpace; 尝试从cache中获取表最近使用的page，如果没有则尝试通过FSM获取满足插入条件的page 12345678910if (bistate &amp;&amp; bistate-&gt;current_buf != InvalidBuffer) targetBlock = BufferGetBlockNumber(bistate-&gt;current_buf);else targetBlock = RelationGetTargetBlock(relation);if (targetBlock == InvalidBlockNumber &amp;&amp; use_fsm)&#123; // cache中没有目标page，让FSM来提供一个初始目标page targetBlock = GetPageWithFreeSpace(relation, targetFreeSpace);&#125; 接下来我们拿着之前获取到的block，去获取对应的buffer 123456789101112131415if (otherBuffer == InvalidBuffer)&#123; // 没有otherbuffer, 简单插入语句, 获取buffer buffer = ReadBufferBI(relation, targetBlock, RBM_NORMAL, bistate); if (PageIsAllVisible(BufferGetPage(buffer))) visibilitymap_pin(relation, targetBlock, vmbuffer); if ((options &amp; HEAP_INSERT_FROZEN) &amp;&amp; (PageGetMaxOffsetNumber(BufferGetPage(buffer)) == 0)) visibilitymap_pin(relation, targetBlock, vmbuffer); LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);&#125;page = BufferGetPage(buffer); 如果拿到的page有足够的空闲空间，我们就完成了获取可用page的步骤，直接返回就可以了 12345678// 检查page是否有足够的空闲空间，如果有则返回当前pagepageFreeSpace = PageGetHeapFreeSpace(page);if (targetFreeSpace &lt;= pageFreeSpace)&#123; /* use this page as future insert target, too */ RelationSetTargetBlock(relation, targetBlock); return buffer;&#125; 如果没有足够的空间，我们需要去寻找下一个block 123456789101112131415161718192021222324252627// 如果有正在进行的批量操作, 则还有其他的未使用的page, 我们尝试使用下一个pageif (bistate &amp;&amp; bistate-&gt;next_free != InvalidBlockNumber)&#123; targetBlock = bistate-&gt;next_free; if (bistate-&gt;next_free &gt;= bistate-&gt;last_free) &#123; bistate-&gt;next_free = InvalidBlockNumber; bistate-&gt;last_free = InvalidBlockNumber; &#125; else bistate-&gt;next_free++;&#125;// 如果没有进行批量操作, 这个时候就要问一问FSM的意见else if (!use_fsm)&#123; // 没有FSM, 只能跳出循环去扩页 break;&#125;else&#123; // 通过FSM寻找下一个合适的page targetBlock = RecordAndGetPageWithFreeSpace(relation, targetBlock, pageFreeSpace, targetFreeSpace);&#125; 如果以上循环中没有找到空闲buffer，我们只能进入扩页的逻辑来新增一个page用来插入 1234567// 扩页并返回新增的page, 扩页的具体逻辑我们在这就不详细介绍了// 简单来说就是给relation加Exclusive锁, 然后初始化一个新的page进去buffer = RelationAddBlocks(relation, bistate, num_pages, use_fsm, &amp;unlockedTargetBuffer);targetBlock = BufferGetBlockNumber(buffer);page = BufferGetPage(buffer); 新增的页我们再来检查下是否有足够的空闲空间，如果有的话就能返回使用了 1234567891011121314151617pageFreeSpace = PageGetHeapFreeSpace(page);if (len &gt; pageFreeSpace)&#123; if (unlockedTargetBuffer) &#123; if (otherBuffer != InvalidBuffer) LockBuffer(otherBuffer, BUFFER_LOCK_UNLOCK); UnlockReleaseBuffer(buffer); goto loop; &#125; elog(PANIC, &quot;tuple is too big: size %zu&quot;, len);&#125;RelationSetTargetBlock(relation, targetBlock);return buffer; 写入数据 写入数据是由接口RelationPutHeapTuple来完成 12345678910111213141516171819202122232425262728voidRelationPutHeapTuple(Relation relation, Buffer buffer, HeapTuple tuple, bool token)&#123; Page pageHeader; OffsetNumber offnum; ... pageHeader = BufferGetPage(buffer); // 将元组插入到page中 offnum = PageAddItem(pageHeader, (Item) tuple-&gt;t_data, tuple-&gt;t_len, InvalidOffsetNumber, false, true); // 记录当前的位置到元组的t_self中 ItemPointerSet(&amp;(tuple-&gt;t_self), BufferGetBlockNumber(buffer), offnum); // 将当前的位置也记录到元组的ctid中 if (!token) &#123; ItemId itemId = PageGetItemId(pageHeader, offnum); HeapTupleHeader item = (HeapTupleHeader) PageGetItem(pageHeader, itemId); item-&gt;t_ctid = tuple-&gt;t_self; &#125;&#125; 这里主要的工作都有函数PageAddItem来完成，PageAddItem是一个宏，内部调用PageAddItemExtended，我们来详细看下这个接口 page是插入的页面，item的插入的数据指针，size的插入数据的大小。offsetNumber是元组在页面中的偏移量，如果插入成功则会被返回。flags是插入的选项 123456OffsetNumberPageAddItemExtended(Page page, Item item, Size size, OffsetNumber offsetNumber, int flags) 首先我们在page中寻找下一个slot的位置，如果之后没有找到空余的slot，我们就会使用这个位置来插入元组 1234567891011121314151617181920limit = OffsetNumberNext(PageGetMaxOffsetNumber(page));// 如果page有free line pointer, 也就是pd_flags中包含PD_HAS_FREE_LINES标记// 则去行指针数组中寻找free slotif (PageHasFreeLinePointers(page))&#123; // 扫描PageHeader的行指针数组，查找标记为 LP_UNUSED的 itemId for (offsetNumber = FirstOffsetNumber; offsetNumber &lt; limit; offsetNumber++) &#123; if (!ItemIdIsUsed(itemId) &amp;&amp; !ItemIdHasStorage(itemId)) break; &#125;&#125;else&#123; // 没有free line pointer, 使用limit offsetNumber = limit;&#125; 接下来我们计算page的pd_lower和pg_upper指针指向的offset 12345678if (offsetNumber == limit || needshuffle) lower = phdr-&gt;pd_lower + sizeof(ItemIdData);else lower = phdr-&gt;pd_lower;alignedSize = MAXALIGN(size);upper = (int) phdr-&gt;pd_upper - (int) alignedSize; 最后我们就可以把元组插入到page中了 12345678910111213141516// 如果已经有了对应的行指针, 则重新设置行指针中的值和标记itemId = PageGetItemId(page, offsetNumber);if (needshuffle) memmove(itemId + 1, itemId, (limit - offsetNumber) * sizeof(ItemIdData));ItemIdSetNormal(itemId, upper, size);// 将数据插入到对应的offsetmemcpy((char *) page + upper, item, size);// 更新PageHeader中的upper和lower指针phdr-&gt;pd_lower = (LocationIndex) lower;phdr-&gt;pd_upper = (LocationIndex) upper; ###WAL log和统计信息 将元组真正插入到page之后，我们会写WAL log并更新相关的统计信息。这两块我们就不在这里详细的描述了","categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/categories/PostgreSQL/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/tags/PostgreSQL/"},{"name":"storage","slug":"storage","permalink":"https://spike1337.github.io/tags/storage/"}]},{"title":"PostgreSQL源码 · 元组管理（二）· 元组的组织结构","slug":"tuple_manager_2","date":"2023-07-11T10:35:06.000Z","updated":"2023-08-24T01:55:05.462Z","comments":true,"path":"2023/07/11/tuple_manager_2/","link":"","permalink":"https://spike1337.github.io/2023/07/11/tuple_manager_2/","excerpt":"","text":"上次我们简单看了下PostgreSQL中页面的组织结构，介绍了PageHeader和行指针的结构。这次我们来看看元组的结构，也就是tuple的成员变量 Tuple的结构 元组的结构如下 1234567typedef struct HeapTupleData&#123; uint32 t_len; ItemPointerData t_self; Oid t_tableOid; HeapTupleHeader t_data;&#125; HeapTupleData; t_len，元组t_data字段的长度 t_self，记录元组自己的位置信息，包括所在的block信息，和元组在页面中的offset t_tableOid，元组所在表的oid t_data，元组的元数据信息和具体存储的数据 HeapTupleHeader 存储元组的元数据信息，结构如下 1234567891011121314struct HeapTupleHeaderData&#123; union &#123; HeapTupleFields t_heap; DatumTupleFields t_datum; &#125; t_choice; ItemPointerData t_ctid; uint16 t_infomask2; uint16 t_infomask; uint8 t_hoff; bits8 t_bits[FLEXIBLE_ARRAY_MEMBER];&#125;; t_heap，元组事务相关的域 t_datum，元组数据相关的域 t_cid，HOT元组会指向最新的元组位置，否则指向自己的位置 t_infomask2，元组的属性数，和一些标记位 t_infomask，元组的标记位。这些标记我们就不在这里介绍了 t_hoff，header的整体大小 t_bits，NULL值列的数组 t_bits数组之后存放的就是元组的数据 HeapTupleFields 元组事务相关的域 1234567891011typedef struct HeapTupleFields&#123; TransactionId t_xmin; TransactionId t_xmax; union &#123; CommandId t_cid; TransactionId t_xvac; &#125; t_field3;&#125; HeapTupleFields; t_xmin，元组插入的事务号 t_xmax，元组删除的事务号 t_cid，命令id，表示当前事务中执行的修改该元组的命令的id t_xvac，vacuum full操作的事务号 DatumTupleFields 元组数据相关的域 1234567typedef struct DatumTupleFields&#123; int32 datum_len_; /* varlena header (do not touch directly!) */ int32 datum_typmod; /* -1, or identifier of a record type */ Oid datum_typeid; /* composite type OID, or RECORDOID */&#125; DatumTupleFields; datum_len_，变长数据类型的长度 datum_typmod，数据类型 datum_typeid，复合类型的类型oid","categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/categories/PostgreSQL/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/tags/PostgreSQL/"},{"name":"storage","slug":"storage","permalink":"https://spike1337.github.io/tags/storage/"}]},{"title":"PostgreSQL源码 · 元组管理（一）· 页的组织结构","slug":"tuple_manager_1","date":"2023-07-10T09:47:33.000Z","updated":"2023-08-24T01:55:01.531Z","comments":true,"path":"2023/07/10/tuple_manager_1/","link":"","permalink":"https://spike1337.github.io/2023/07/10/tuple_manager_1/","excerpt":"","text":"开个新坑，简单写一写PostgreSQL中的元组管理。 对于整个存储架构，各种PostgreSQL的相关书籍已经介绍的很详细了，这里也就不再重复造轮子了。下面我们主要基于面向对象（大雾），来看看元组这个对象，有哪些成员变量，又有哪些成员函数 元组(Tuple)是PostgreSQL中数据的基本存储单元，Page又是存储元组的基本载体，所以这第一篇我们先来看一下Page的结构 Page的结构 Page的结构可以简单看下图所示 page的默认大小为8k。每个页面的起始位置有大小为24个字节的PageHeader，记录该page相关的元数据信息。PageHeader中的pd_lower和pd_upper分别指向了页面空闲空间的首尾。 这里每一个tuple存储一条数据记录，从数据页底部开始向前依次存储。这些元组在页面中的位置存储在行指针line pointer中，每个行指针指向一个tuple。行指针从前向后依次存储，形成一个简单的数据。行指针中还存放了元组的状态和大小信息，扮演元组在页面中的索引的角色。行指针和tuple中间的部分为页面的空闲空间。 我们首先来看看PageHeader存储了什么元数据 PageHeader 123456789101112typedef struct PageHeaderData&#123; PageXLogRecPtr pd_lsn; uint16 pd_checksum; uint16 pd_flags; LocationIndex pd_lower; LocationIndex pd_upper; LocationIndex pd_special; uint16 pd_pagesize_version; TransactionId pd_prune_xid; ItemIdData pd_linp[FLEXIBLE_ARRAY_MEMBER];&#125; PageHeaderData; pd_lsn，记录了该页面最后一次更改的WAL log的lsn pg_checksum，页面校验和 pd_flags，页面的标记为，包括以下标记 PD_HAS_FREE_LINES，页面中是否有unused line pointer. 这个unused的概念我们之后在看到line pointer时会介绍 PD_PAGE_FULL，页面是否有足够的空闲空间给新的tuple PD_ALL_VISIBLE，页面中的所有元组是否对当前和之后的所有事务可见 pd_lower，指向空闲空间的起始位置 pd_upper，指向空闲空间的结束位置 pd_special，指向特殊空间的起始位置 pd_pagesize_version，页面布局的版本号 pd_prune_xid，用于页面元组清理时的标记位，记录了最旧的可清理的事务号。没有则为0 pg_linp，页面行指针数组 页面的行指针结构 行指针是一个32位大小的索引结构，如下： 123456typedef struct ItemIdData&#123; unsigned lp_off:15, lp_flags:2, lp_len:15;&#125; ItemIdData; lp_off，记录了tuple在页面中的offset lp_len，记录了tuple的size lp_flags，是一个tuple状态的简单标记，方便在扫描元组时做一个初步筛选，有以下几个标记 LP_UNUSED，元组未使用，可以立刻被重用 LP_NORMAL，元组状态正常 LP_REDIRECT，元组被重定向了。用于PG的HOT链的头部和中间元组 LP_DEAD，元组已死，但空间可能还没有回收","categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/categories/PostgreSQL/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/tags/PostgreSQL/"},{"name":"storage","slug":"storage","permalink":"https://spike1337.github.io/tags/storage/"}]},{"title":"Linux · 工具 · devtodo · 简洁的终端todo工具","slug":"devtodo-manual","date":"2023-02-07T02:23:30.000Z","updated":"2023-08-22T06:03:21.632Z","comments":true,"path":"2023/02/07/devtodo-manual/","link":"","permalink":"https://spike1337.github.io/2023/02/07/devtodo-manual/","excerpt":"","text":"devtodo是一款运行于终端的todo工具，简洁是它的最大优势。devtodo 目前已被许多 Linux 发行版的软件仓库收录，可以从软件仓库中安装它，也可以从它的项目主页devtodo下载最新版本编译安装。 快速上手 123456$ todo # 显示 todo list$ tda # 添加一项 todo，也可以用 todo -a 命令$ tde &lt;index&gt; # 修改第 index 条 todo$ tdd &lt;index&gt; # 标记第 index 条 todo 已经完成$ tdr &lt;index&gt; # 删除第 index 条 todo$ todo -A # 显示所有的 todo 条目，包括完成的以及未完成的 命令展示 todo 显示todo list。按优先级顺序排列 123456$ todo1.test 12.test 23.test 34.test 4 tda 添加一项todo。设定todo内容，并设置todo优先级 12345678$ tdaEnter text for the item you are adding.text&gt; test 11. veryhigh 2. high 3. medium 4. low 5. verylowEnter a priority from those listed above.priority&gt; 1Index of new item is 1 tde k 修改第 k 条 todo。可以重新编辑todo内容，并调整todo优先级 1234567$ tde 1Modify the text of the item you are editing.text&gt; test modify 11. veryhigh 2. high 3. medium 4. low 5. verylowEnter a priority from those listed above.priority&gt; 1 tdd k 标记第 k 条 todo 已完成，可以设定完成的comment信息 123$ tdd 1comment&gt; done tdr k 删除第 k 条 todo 12$ tdr k todo -A 查看所有的 todo notes，不包括被删除项 123- 2.test 2 3.test 3 4.test 4 进阶配置 全局todo nots记录 默认的devtodo是在执行tda时，在执行目录下创建文件.todo来记录todo notes，执行其他操作时也是读取执行目录下的.todo文件。也就是每个执行目录有自己的todo list。如果我们想要一个全局的todo list，我们需要使用-G参数。 1-G, --global Use the database specified by the --global-database option. Defaults to ~/.todo_global. -G参数使用 ~/.todo_global作为存储todo notes的数据库，这样我们的todo就可以在全局范围内使用。作为懒狗我就直接将-G参数写入了alias 12345alias todo=&quot;todo -G&quot;alias tda=&quot;tda -G&quot;alias tdd=&quot;tdd -G&quot;alias tde=&quot;tde -G&quot;alias tdr=&quot;tdr -G&quot; 当然，如果不想使用默认的~/.todo_global文件作为全局数据库，也可以通过--global-database指定全局数据库的文件。 1--global-database ARG Specify the database to use if the -G (--global) parameter is used.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://spike1337.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://spike1337.github.io/tags/Linux/"},{"name":"tools","slug":"tools","permalink":"https://spike1337.github.io/tags/tools/"}]},{"title":"PostgreSQL · 源码解析 · MVCC机制","slug":"mvcc-source-code","date":"2023-02-06T06:36:45.000Z","updated":"2023-08-24T01:54:42.631Z","comments":true,"path":"2023/02/06/mvcc-source-code/","link":"","permalink":"https://spike1337.github.io/2023/02/06/mvcc-source-code/","excerpt":"","text":"PostgreSQL采用多版本并发控制（MVCC）来维护数据的一致性。检索数据时，每个事务看到的都只是一段时间之前的数据快照。MVCC并不能解决所有的并发控制情况，需要使用传统数据库的锁机制来保证事务的并发，因此在PostgreSQL里也有表和行级别的锁定机制。此外PostgreSQL还提供了会话锁机制，可以利用它一次对某个对象加锁保证对于多个事务都有效。 事务隔离级别 标准事务隔离级别 三个必须在并行的事务之间避免的现象： 脏读：一个事务读取了另一个未提交的并行事务写的数据 不可重复读：一个事务对一个数据前后读取两次，发现该数据已经被另一个已提交的数据修改过 幻读：事务A读取某一范围内的数据行时，事务B在该范围内插入新行，当事务A再次读取该范围内的数据时无法查询到新增的数据 四个事务隔离级别： 隔离级别 脏读 不可重复读 幻读 读未提交 ⭕ ⭕ ⭕ 读已提交 ❌ ⭕ ⭕ 可重复读 ❌ ❌ ⭕ 可串行化 ❌ ❌ ❌ PostgreSQL的隔离级别 在PostgreSQL中，可以请求以上四种事务隔离级别的任意一种。但是在内部，只有两种独立的隔离级别：读已提交和可串行化。即选择读未提交的隔离级别，实际用的是读已提交。下面介绍PostgreSQL定义的两种隔离级别： 读已提交：缺省隔离级别。当一个事务运行在这个隔离级别时，一个SELECT查询只能看到查询开始之前提交的数据。如果两个事务在对同一元组进行更新，如果第一个事务回滚，则忽略其作用，第二个事务继续更新该元组；第二个事务则等待第一个事务提交或回滚。如果第一个事务提交，系统重新计算查询条件，如果符合则继续更新操作。 可串行化：提供了最严格的事务隔离。模拟串行的事务执行。如果两个事务在对同一元组进行更新，第二个事务则等待第一个事务提交或回滚。如果第一个事务回滚，则忽略其作用，第二个事务继续更新该元组；如果第一个事务提交，那么可串行化事务回滚，从头开始进行整个事务。 在PostgreSQL系统中，事务的隔离级别所涉及的最小对象是元组，所以对元组的操作需要实施访问控制。这个操作是通过锁操作以及MVCC相关的操作来实现的 MVCC架构 在内部，PostgreSQL利用多版本并发控制（MVCC，MultiVersion Concurrency Control）来维护数据的一致性。即当检索数据时，每个事务看到的只是一段时间之前的事务快照，而不是数据的当前状态。这样对每个数据库会话进行事务隔离，就可以避免一个事务看到其他并发时的更新导致不一致的数据 元组相关数据结构 在PostgreSQL系统中，更新数据并不是用新值覆盖旧值，而是在表中开辟一片空间来存放新的元组，新值与旧值同时存在于数据库中，只是通过设置一些参数让系统可以识别他们 元组的事务和命令控制信息存储在HeapTupleFields中 1234567891011typedef struct HeapTupleFields&#123; TransactionId t_xmin; // 创建此tuple的XID TransactionId t_xmax; // 删除此tuple的XID union &#123; CommandId t_cid; // 创建或删除tuple的CID，也可能二者都保存 TransactionId t_xvac; // 清理操作的事务ID &#125;t_field3;&#125; HeapTupleFields; 如果一个事务确实创建并删除了同一个元组，则使用一个Combo Command ID 来保存Cmin和Cmax 元组的相关控制信息存储在元组的头部HeapTupleHeaderData中 1234567891011121314struct HeapTupleHeaderData&#123; union &#123; HeapTupleFields t_heap; DatumTupleFields t_datum; &#125; t_choice; ItemPointerData t_ctid; // 本元组或更新元组的当前TID uint16 t_infomask2; // 属性、标记位数量标记位 uint16 t_infomask; // 元组事务信息标记位 uint8 t_hoff; // 头部长度 bits8 t_bits[FLEXIBLE_ARRAY_MEMBER]; // 标记作用的填充位&#125;; 其中，t_ctid当元组被保存在磁盘中时被初始化为自己的实际存储位置。如果元组被更新，t_cid指向更新后的新元组。如果要找到某个元组的最新版本，只需遍历由t_ctid构成的链表即可 t_infomask字段表示当前元组的事务信息 1234567891011121314151617181920212223242526#define HEAP_HASNULL 0x0001 // 空字段标记位#define HEAP_HASVARWIDTH 0x0002 // 变长字段标记位#define HEAP_HASEXTERNAL 0x0004 // 外部存储字段标记位#define HEAP_HASOID_OLD 0x0008 // 有OID字段#define HEAP_XMAX_KEYSHR_LOCK 0x0010 // xmax是共享锁#define HEAP_COMBOCID 0x0020 // t_cid是combo cid#define HEAP_XMAX_EXCL_LOCK 0x0040 // xmax是排他锁#define HEAP_XMAX_LOCK_ONLY 0x0080 // xmax如果有效则只是一个锁 // xmax is a shared locker#define HEAP_XMAX_SHR_LOCK (HEAP_XMAX_EXCL_LOCK | HEAP_XMAX_KEYSHR_LOCK)#define HEAP_LOCK_MASK (HEAP_XMAX_SHR_LOCK | HEAP_XMAX_EXCL_LOCK | \\ HEAP_XMAX_KEYSHR_LOCK)#define HEAP_XMIN_COMMITTED 0x0100 // t_xmin已提交#define HEAP_XMIN_INVALID 0x0200 // t_xmin无效/中断#define HEAP_XMIN_FROZEN (HEAP_XMIN_COMMITTED|HEAP_XMIN_INVALID)#define HEAP_XMAX_COMMITTED 0x0400 // t_xmax已提交#define HEAP_XMAX_INVALID 0x0800 // t_xmax无效/中断#define HEAP_XMAX_IS_MULTI 0x1000 // t_xmax是组合事务#define HEAP_UPDATED 0x2000 // 更新后的新元组#define HEAP_MOVED_OFF 0x4000 // 被之前版本的VACUUM FULL移到其他地方，用以兼容二进制升级#define HEAP_MOVED_IN 0x8000 // 被之前版本的VACUUM FULL从其他地方移入，用以兼容二进制升级#define HEAP_MOVED (HEAP_MOVED_OFF | HEAP_MOVED_IN)#define HEAP_XACT_MASK 0xFFF0 // 可见性相关标记 MVCC MVCC基本原理如图。有两个并发事务T1，T2，T1将元组C更新为C‘，但并没有提交。此时T2要对该元组进行查询，会通过C和C’的头部信息的Xmin和Xmax以及t_infomask来判断哪个为对当前事务的有效版本 MVCC与快照 讨论MVCC的判断逻辑之前，我们需要先了解快照（snapshot） 快照（snapshot）记录了数据库当前某个时刻的活跃事务列表，通过快照确定某个元组的版本对于当前快照是否可见。快照定义在SnapshotData中 123456789101112131415161718192021222324252627282930typedef struct SnapshotData&#123; SnapshotType snapshot_type; // 快照类型 TransactionId xmin; // 所有XID &lt; xmin对当前快照可见 TransactionId xmax; // 所有XID &gt;= xmax对当前快照可见 TransactionId *xip; // 当前活跃事务的链表 uint32 xcnt; // 当前活跃事务链表长度 TransactionId *subxip; // 当前活跃子事务链表 int32 subxcnt; // 当前活跃子事务链表的长度 bool suboverflowed; // 活跃子事务数组是否移除 bool takenDuringRecovery; // 是否是在Recovery中的快照 bool copied; // 静态快照则为false CommandId curcid; // 所有CID &lt; curcid是可见的 // HeapTupleSatisfiesDirty中的额外返回值，并没有在MVCC快照中使用 uint32 speculativeToken; // 由快照管理器使用的信息 uint32 active_count; // 在活跃快照链表里的引用计数 uint32 regd_count; // 在已注册的快照链表里的引用计数 pairingheap_node ph_node; // 已注册的快照链表 TimestampTz whenTaken; // 记录快照的时间戳 XLogRecPtr lsn; // 记录快照时在WAL中的位置&#125; SnapshotData; 在PostgreSQL中有默认的7种形式快照（15.1），分别是： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061typedef enum SnapshotType&#123; // 元组对于给定的MVCC快照有效 SNAPSHOT_MVCC = 0, // 元组对于自身有效 SNAPSHOT_SELF, // 任何元组都是可见的 SNAPSHOT_ANY, // 元组作为TOAST行 有效 SNAPSHOT_TOAST, // 下面三个不太好解释，直接贴原文 /*------------------------------------------------------------------------- * A tuple is visible iff the tuple is valid including effects of open * transactions. * * Here, we consider the effects of: * - all committed and in-progress transactions (as of the current instant) * - previous commands of this transaction * - changes made by the current command * * This is essentially like SNAPSHOT_SELF as far as effects of the current * transaction and committed/aborted xacts are concerned. However, it * also includes the effects of other xacts still in progress. * * A special hack is that when a snapshot of this type is used to * determine tuple visibility, the passed-in snapshot struct is used as an * output argument to return the xids of concurrent xacts that affected * the tuple. snapshot-&gt;xmin is set to the tuple&#x27;s xmin if that is * another transaction that&#x27;s still in progress; or to * InvalidTransactionId if the tuple&#x27;s xmin is committed good, committed * dead, or my own xact. Similarly for snapshot-&gt;xmax and the tuple&#x27;s * xmax. If the tuple was inserted speculatively, meaning that the * inserter might still back down on the insertion without aborting the * whole transaction, the associated token is also returned in * snapshot-&gt;speculativeToken. See also InitDirtySnapshot(). * ------------------------------------------------------------------------- */ SNAPSHOT_DIRTY, /* * A tuple is visible iff it follows the rules of SNAPSHOT_MVCC, but * supports being called in timetravel context (for decoding catalog * contents in the context of logical decoding). */ // 元组对MVCC快照有效，且支持逻辑复制 SNAPSHOT_HISTORIC_MVCC, /* * A tuple is visible iff the tuple might be visible to some transaction; * false if it&#x27;s surely dead to everyone, i.e., vacuumable. * * For visibility checks snapshot-&gt;min must have been set up with the xmin * horizon to use. */ // 元组对某些事务可见，如果对所有事务都是dead tuple，也就是vacuumable，则返回false SNAPSHOT_NON_VACUUMABLE&#125; SnapshotType; MVCC机制的实现 以函数HeapTupleSatisfiesSelf为例，下面介绍MVCC机制的具体实现。如果返回值为True，则该元组是可见的。判断时会考虑三个方面的因素：所有已提交的事务，当前事务前的所有命令以及当前命令前的所有操作。执行过程如下： 检查Xmin是否为已提交，如果元组的Xmin还未提交 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Xmin未提交if (!HeapTupleHeaderXminCommitted(tuple))&#123; // Xmin无效，元组不可见 if (HeapTupleHeaderXminInvalid(tuple)) return false; // 兼容二进制升级 if (tuple-&gt;t_infomask &amp; HEAP_MOVED_OFF) &#123; ... &#125; // 兼容二进制升级 else if (tuple-&gt;t_infomask &amp; HEAP_MOVED_IN) &#123; ... &#125; // Xmin为当前事务 else if (TransactionIdIsCurrentTransactionId(HeapTupleHeaderGetRawXmin(tuple))) &#123; // Xmax无效，则XID无效，可见 if (tuple-&gt;t_infomask &amp; HEAP_XMAX_INVALID) return true; // Xmax被锁定，即元组被锁定，可见 if (HEAP_XMAX_IS_LOCKED_ONLY(tuple-&gt;t_infomask)) return true; // Xmax是组合事务 if (tuple-&gt;t_infomask &amp; HEAP_XMAX_IS_MULTI) &#123; xmax = HeapTupleGetUpdateXid(tuple); // 更新子事务必须已回滚，因为前提是Xmin未提交 if (!TransactionIdIsCurrentTransactionId(xmax)) return true; else return false; &#125; // Xmax为当前事务 if (!TransactionIdIsCurrentTransactionId(HeapTupleHeaderGetRawXmax(tuple))) &#123; // 删除子事务必须已终止 SetHintBits(tuple, buffer, HEAP_XMAX_INVALID, InvalidTransactionId); return true; &#125; return false; &#125; // Xmin正在某个后端进程中运行 else if (TransactionIdIsInProgress(HeapTupleHeaderGetRawXmin(tuple))) return false; // Xmin已经被提交 else if (TransactionIdDidCommit(HeapTupleHeaderGetRawXmin(tuple))) SetHintBits(tuple, buffer, HEAP_XMIN_COMMITTED, HeapTupleHeaderGetRawXmin(tuple)); else &#123; // 否则一定是中止或崩溃 SetHintBits(tuple, buffer, HEAP_XMIN_INVALID, InvalidTransactionId); return false; &#125;&#125; Xmin已提交。如果Xmax无效或中断，元组可见 12if (tuple-&gt;t_infomask &amp; HEAP_XMAX_INVALID) return true; Xmin已提交，Xmax已提交 1234567if (tuple-&gt;t_infomask &amp; HEAP_XMAX_COMMITTED)&#123; // 如果Xmax被锁定，可见 if (HEAP_XMAX_IS_LOCKED_ONLY(tuple-&gt;t_infomask)) return true; return false;&#125; Xmin已提交，Xmax为组合事务 12345678910111213141516171819202122if (tuple-&gt;t_infomask &amp; HEAP_XMAX_IS_MULTI)&#123; TransactionId xmax; // Xmax被锁定，可见 if (HEAP_XMAX_IS_LOCKED_ONLY(tuple-&gt;t_infomask)) return true; xmax = HeapTupleGetUpdateXid(tuple); // Xmax是当前事务 if (TransactionIdIsCurrentTransactionId(xmax)) return false; // Xmax正在被某个后端进程执行 if (TransactionIdIsInProgress(xmax)) return true; // Xmax已经被提交 if (TransactionIdDidCommit(xmax)) return false; // 否则事务被中断或崩溃 return true;&#125; Xmin已提交，Xmax不是组合事务 12345678910111213141516171819202122232425// Xmax是当前事务if (TransactionIdIsCurrentTransactionId(HeapTupleHeaderGetRawXmax(tuple)))&#123; if (HEAP_XMAX_IS_LOCKED_ONLY(tuple-&gt;t_infomask)) return true; return false;&#125;// Xmax正在被某个后端进程执行if (TransactionIdIsInProgress(HeapTupleHeaderGetRawXmax(tuple))) return true;// Xmax已经被提交if (!TransactionIdDidCommit(HeapTupleHeaderGetRawXmax(tuple)))&#123; // it must have aborted or crashed SetHintBits(tuple, buffer, HEAP_XMAX_INVALID, InvalidTransactionId); return true;&#125;// Xmax被锁定if (HEAP_XMAX_IS_LOCKED_ONLY(tuple-&gt;t_infomask))&#123; SetHintBits(tuple, buffer, HEAP_XMAX_INVALID, InvalidTransactionId); return true;&#125; SNAPSHOT_SELF所对应的MVCC判断机制如上，其他snapshot类型对应的判断逻辑类似，就不再详细介绍了","categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/categories/PostgreSQL/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/tags/PostgreSQL/"},{"name":"transaction","slug":"transaction","permalink":"https://spike1337.github.io/tags/transaction/"},{"name":"MVCC","slug":"MVCC","permalink":"https://spike1337.github.io/tags/MVCC/"}]},{"title":"PostgreSQL · 源码解析 · WAL日志","slug":"pg-wal-source-code","date":"2023-02-03T05:44:58.000Z","updated":"2023-08-24T01:54:50.544Z","comments":true,"path":"2023/02/03/pg-wal-source-code/","link":"","permalink":"https://spike1337.github.io/2023/02/03/pg-wal-source-code/","excerpt":"","text":"Postgresql 使用 wal 日志保存每一次的数据修改，这样保证了数据库即使意外宕机，也能利用它准确的恢复数据。wal 日志也叫做 xlog，在 9.4 版本之后作了重大更新，本篇只讲解最新版的格式。wal 日志被用于多个方面，比如修改数据，修改索引等，每种用途的格式都不相同，但是构建方式是相同的。 WAL日志文件 WAL段文件 WAL日志文件存放在sd_wal目录下，每个文件大小默认为16M： 1234567-rw------- 1 zhangze zhangze 16777216 Oct 8 10:57 0000000100000000000000B6-rw------- 1 zhangze zhangze 16777216 Oct 8 10:57 0000000100000000000000B7-rw------- 1 zhangze zhangze 16777216 Oct 8 10:57 0000000100000000000000B8-rw------- 1 zhangze zhangze 16777216 Oct 8 10:57 0000000100000000000000B9-rw------- 1 zhangze zhangze 16777216 Oct 8 10:57 0000000100000000000000BA-rw------- 1 zhangze zhangze 16777216 Oct 8 10:57 0000000100000000000000BBdrwx------ 2 zhangze zhangze 68 Oct 8 10:53 archive_status 文件名由16进制的24个字符组成，每8个字符为一组，每组意义如下： 1200000001 00000000 000000B6 时间线 LogID LogSeg 时间线：时间线ID，取值范围为 0x00000000 -&gt; 0xFFFFFFFF。数据库建好后的第一个WAL日志文件的时间线ID从1开始 LogID：逻辑文件ID，取值范围为 0x00000000 -&gt; 0xFFFFFFFF LogSeg：物理文件ID，取值范围为 0x00000000 -&gt; 0x000000FF。数据库建好后的第一个WAL日志文件的LogSeg从1开始，达到最大值（0xFF）后从0开始。 LSN即日志序列号，表示XLog记录在事务日志文件中的偏移，为uint64值。LSN由三部分组成，分别是逻辑文件ID，物理文件ID和文件内偏移量。LSN打印出来是两个8位的十六进制数，如16/B374D848。由专门的类型pg_lsn来存放LSN数据 PG WAL文件名字的命名方法是在XLogFileName宏里定义的。 1234567891011121314#define XLogSegmentsPerXLogId(wal_segsz_bytes) \\ (UINT64CONST(0x100000000) / (wal_segsz_bytes))#define XLogFileName(fname, tli, logSegNo, wal_segsz_bytes) \\ snprintf(fname, MAXFNAMELEN, &quot;%08X%08X%08X&quot;, tli, \\ (uint32) ((logSegNo) / XLogSegmentsPerXLogId(wal_segsz_bytes)), \\ (uint32) ((logSegNo) % XLogSegmentsPerXLogId(wal_segsz_bytes)))#define XLogFileNameById(fname, tli, log, seg) \\ snprintf(fname, MAXFNAMELEN, &quot;%08X%08X%08X&quot;, tli, log, seg)#define IsXLogFileName(fname) \\ (strlen(fname) == XLOG_FNAME_LEN &amp;&amp; \\ strspn(fname, &quot;0123456789ABCDEF&quot;) == XLOG_FNAME_LEN) WAL文件内部结构 每个WAL段文件由多个8kb大小的page组成，每个Page中存放着PageHeader信息，以及多条WAL Record Page结构 每个page的组织方式如下图： PageHeader：在wal page的组成中有两种pageheader结构，XLogPageHeaderData和XLogLongPageHeaderData。每个WAL段的第一个Page的Header应为LongHeader Remain data：存储着上一个page中最后一个Record没有存完的数据，大小为xlp_rem_len，对应page的不完整Record Record：存储具体的WAL Record 无数据区域：一个WAL Record的头部信息不允许跨页，如果剩余空间不够存储头部信息，则舍弃这部分空间 Record结构 每个WAL Record的结构如下图，绿色部分为数据描述结构，黄色部分是实际保存的数据 XLogRecord：一个WAL记录的入口，解析WAL时，从这个结构体入手 Block：第一个虚线框称为一个BLOCK，用以描述Buffer相关的数据结构。通过XLogRegisterBuffer()函数注册到wal记录中 XLogRecordBlockHeader：一个BLOCK的头部信息 XLogRecordBlockImageHeader：如果该WAL是fpw记录，该结构存放fpw相关信息 fpw：Full_page_write，具体见整页写入 XLogRecordBlockCompressHeader：记录hole的大小 hole：数据文件的page中，可能会有一块空白区域，即pointer和tuple之间的区域，称为hole RelFilenode：此结构记录了此block所属的关系 BlockNumber：此block记录的page的块号 XLogRecordDataHeader(Long/short)：当main data的大小大于255时，使用Long Header buffer data：第二个虚线框部分，包括page data和tuple data page data：由XLogRegisterBuffer()函数注册到wal记录，存放buffer page信息 tuple data：由XLogRegisterBufData()函数注册到wal记录，存储了实际的buff数据和变更数据。 main data：保存非buffer性的数据，由XLogRegisterData()函数到WAL记录，例如特殊结构体，旧元组或key WAL日志写入实现 当数据库数据发生变更时： change发生时：先要将变更后内容计入wal buffer中，再将变更后的数据写入data buffer； commit发生时：wal buffer中数据刷新到磁盘； checkpoint发生时：将所有data buffer刷新的磁盘。 WAL日志机制就是先将变更内容存放到wal buffer，commit后将wal buffer刷入磁盘的过程。过程中主要的函数如下： 123456789XLogBeginInsert(); // 表示开始构建 xlogXLogRegisterData(); // 将WAL记录的特殊结构体数据注册到WAL，比如heap_insert中的xl_heap_insert结构体XLogRegisterBuffer(); // 将涉及到的buf注册到wal记录，比如heap_insert中page页赋予regbuf-&gt;pageXLogRegisterBufData(); // 将元组内容注册到WAL记录，比如insert语句的元组数据等XLogSetRecordFlags();XLogInsert(); XLogRecordAssemble(); XLogInsertRecord(); // 根据当前的数据库状态，把上述函数注册的数据进行筛选组装，最终形成完整的wal记录并写入到walbuffPageSetLSN 整页写入(Full_Write_Page) 如果数据库系统在写入脏页的过程中出现故障，会导致磁盘上的页面数据损坏，而XLOG是无法在损坏的页面上重放的，需要整页写入来恢复。 如果启用整页写入，PostgreSQL会在每个检查点后，每个页面第一次变更发生前，将整个页面以及Header信息作为一条XLog写入，这个功能默认开启。在数据库恢复过程中，如果检查到一条XLog是一个用来整页写入的备份区块，会使用另一条重放规则：XLog会直接覆盖当前页面，无视页面和XLog记录中的LSN，然后将页面的LSN更新为XLog记录的LSN 具体数据结构 XLog Page XLogPageHeaderData XLog日志分为很多逻辑段文件，每个段文件分成许多个页面，每个页面的大小为一个块的大小。每个日志页面都有一个头部信息： 1234567891011typedef struct XLogPageHeaderData&#123; uint16 xlp_magic; // 校验位，检验WAL的版本信息 uint16 xlp_info; // 标记位 TimeLineID xlp_tli; // 页面第一条记录的时间序列 XLogRecPtr xlp_pageaddr; // XLog页面的地址 // 当前页面没有足够空间用于记录时，继续在下一页记录 // 记录了前一页的剩余字节数，包括备份块数据，即该记录在本页继续存储占用的空间大小 uint32 xlp_rem_len;&#125; XLogPageHeaderData; 其中，标记位xlp_info只使用最低两位，0表明该页的第一个XLog记录接着上一页的最后一个XLog记录，1表示该页是该XLog文件的首页 XLogLongPageHeaderData 如果页面是该日志文件的首页，那么在原头部信息的基础上会使用一个长的头部信息 1234567typedef struct XLogLongPageHeaderData&#123; XLogPageHeaderData std; // 标准的头部信息，即 XLogPageHeaderData uint64 xlp_sysid; // pg_control中的系统标识符 uint32 xlp_seg_size; // 校验位，段的大小 uint32 xlp_XLog_blcksz; // 校验位，块的大小&#125; XLogLongPageHeaderData; 对于长的XLog日志记录，允许将没有足够空间存储的数据存储到下一个页面，但不允许Record头部信息被分开存储到两个不同页面。如果剩余空间已经不足以存储一个头部信息，那么剩余空间将被舍弃，将这个XLog记录存储到新的下一个页面中 XLog Record XLogRecord 结构XLogRecord记录了XLog的相关控制信息，一个XLog记录最多可以附3个备份块， 每个块对应一个磁盘大小的数据，长度为8kb 12345678910typedef struct XLogRecord&#123; uint32 xl_tot_len; // 整条记录的长度 TransactionId xl_xid; // 事务ID XLogRecPtr xl_prev; // 指向日志中的前一个记录 uint8 xl_info; // 信息标记位 RmgrId xl_rmid; // 资源管理器 pg_crc32c xl_crc; // 本记录的CRC校验码&#125; XLogRecord; 其中，资源管理器号主要用于日志系统中，数据库系统需要将记录的日志数据分类，为它们分配对应的资源管理器号。读取日志记录时，结合资源管理器号和信息标志位，能够直到数据库对源数据做的是哪种操作，从而迅速正确的调用对应的函数。共有16种资源 信息标志位的高4位由资源管理器使用，标识该日志是哪种类型的日志。低4位表示对应的块是否需要备份 XLogRecordBlockHeader 存放block的相关信息 123456789typedef struct XLogRecordBlockHeader&#123; uint8 id; // 块引用ID uint8 fork_flags; // 在关系中使用的fork和flags uint16 data_length; // payload字节大小 //如果设置了 BKPBLOCK_HAS_IMAGE,后续为XLogRecordBlockImageHeader结构体，否则为RelFileNode //之后为BlockNumber&#125; XLogRecordBlockHeader; XLogRecordBlockImageHeader 存放整页写入的相关信息 123456typedef struct XLogRecordBlockImageHeader&#123; uint16 length; // page大小 uint16 hole_offset; // hole之前的长度 uint8 bimg_info; // 标记位，是否压缩&#125; XLogRecordBlockImageHeader; XLogRecordBlockCompressHeader 存放page中的hole大小 1234typedef struct XLogRecordBlockCompressHeader&#123; uint16 hole_length; // hole大小&#125; XLogRecordBlockCompressHeader; XLog Data XLogRecordDataHeader WAL Record的数据部分的header信息 12345678910typedef struct XLogRecordDataHeaderShort&#123; uint8 id; uint8 data_length;&#125;XLogRecordDataHeaderShort;typedef struct XLogRecordDataHeaderLong&#123; uint8 id;&#125;XLogRecordDataHeaderLong; XLogRecData XLog日志记录中的数据信息存储在结构XLogRecData中 123456typedef struct XLogRecData&#123; struct XLogRecData *next; // 下一个节点 char *data; // 数据 uint32 len; // 数据长度&#125; XLogRecData; XLog控制结构 XLogCtlData 在共享内存中用结构XLogCtlData保存XLog信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970typedef struct XLogCtlData&#123; XLogCtlInsert Insert; // 插入一条日志后，最新的相关信息 // 以下受info_lck保护 XLogwrtRqst LogwrtRqst; // 将日志写入和同步的位置 XLogRecPtr RedoRecPtr; // 最近的 Insert-&gt;RedoRecPtr 副本 FullTransactionId ckptFullXid; // 最新检查点的nextXID XLogRecPtr asyncXactLSN; // 最新异步提交/中断的LSN XLogRecPtr replicationSlotMinLSN; // 所有缓冲区所需的最老的LSN XLogSegNo lastRemovedSegNo; // 最后的删除/回收的XLog段 // 用于不需要记录日志的关系的假的LSN XLogRecPtr unloggedLSN; slock_t ulsn_lck; // 切换后最新的XLog的时间和LSN，受XLogWriteLock保护 pg_time_t lastSegSwitchTime; XLogRecPtr lastSegSwitchLSN; // 已经写入和同步的位置，受info_lck或XLogWriteLock保护 XLogwrtResult LogwrtResult; // 缓存中的最后初始化页面，最后一个字节位置+1 XLogRecPtr InitializedUpTo; // 这些值在启动后不会修改，尽管指向的页面和xlblocks通常会改变 // xlblocks受 XLogBufMappingLock 保护 char *pages; // 未写入XLog页面的缓冲区 XLogRecPtr *xlblocks; // 缓冲区内容对应的XLog文件的内部指针 int XLogCacheBlck; // XLog最大缓冲区的下标 // ThisTimeLineID 的共享副本，在完成恢复后不要修改 TimeLineID ThisTimeLineID; TimeLineID PrevTimeLineID; // 标记我们是否处于崩溃或恢复状态，受info_lock保护 RecoveryState SharedRecoveryState; bool SharedHotStandbyActive; // 指示XLog写入是否处于节能模式，受info_lock保护 bool XLogWriterSleeping; // 等待唤醒，如果出现出发文件，则唤醒启动进程以继续执行XLog重放 Latch recoveryWakeupLatch; // 在恢复期间保留最后检查点记录的副本，受info_lck保护 XLogRecPtr lastCheckPointRecPtr; XLogRecPtr lastCheckPointEndPtr; CheckPoint lastCheckPoint; XLogRecPtr lastReplayedEndRecPtr; // 指向成功重放的最后一条记录的结尾+1 TimeLineID lastReplayedTLI; XLogRecPtr replayEndRecPtr; // 如果正处于redo函数回放记录期间，则指向正在恢复记录的结尾+1 // 否则等于lastReplayedEndRecPtr TimeLineID replayEndTLI; TimestampTz recoveryLastXTime; // 重放（正在重放）的最后一个COMMIT/ABORT记录的时间戳 // 开始重放当前XLog数据块的时间戳 TimestampTz currentChunkStartTime; bool recoveryPause; // 是否暂停恢复 // 指向最后重放的XLog_FPW_CHANGE记录的起始点 // 用于禁用full_page_writes XLogRecPtr lastFpwDisableRecPtr; slock_t info_lck; // 共享锁&#125; XLogCtlData; Register_buffer 1234567891011121314151617typedef struct&#123; bool in_use; // is this slot in use? uint8 flags; // REGBUF_* flags RelFileNode rnode; // 指定所属表的存储目录 ForkNumber forkno; // 哪种文件类型 BlockNumber block; // 块编号 Page page; // 对应的原始数据页 uint32 rdata_len; // 私有数据链表的长度总和 XLogRecData *rdata_head; // 私有数据链表头部节点 XLogRecData *rdata_tail; // 私有数据链表尾部节点 XLogRecData bkp_rdatas[2]; // 存储着压缩后或忽略空闲数据的数据，如果有空闲位置且没有压缩，那么数据会被分成两个部分，存储在两个数组元素里 char compressed_page[PGLZ_MAX_BLCKSZ]; // 如果开启了压缩，那么存储着压缩后的数据&#125; registered_buffer; 重要全局变量 1234567891011121314static XLogRecData *mainrdata_head;static XLogRecData *mainrdata_last = (XLogRecData *) &amp;mainrdata_head;/*使用XLogRegisterBuffer注册的数据存储到registered_buffers数组里*/static registered_buffer *registered_buffers;/* * 使用XLogRegisterBufData注册的数据存储到rdatas数组里，并链接为链表，使用registered_buffer结构里的rdata_head和 * rdata_tail作为链表的首尾。 * * 使用XLogRegisterData注册的数据存储到rdatas数组里，并使用mainrdata_head和mainrdata_lastata注册的数据存储到rdatas数组里， * 并链接为链表，使用registered_buffer结构里的rdata_head和rdata_tail作为链表的首尾。 */static XLogRecData *rdatas; 具体函数代码 XLogBeginInsert 函数主要作用是检验调用环境是否正确，判断当前是否可以执行xlog插入，并设置开始构造WAL记录的标记，标志wal插入开始。 1234567891011Assert(max_registered_block_id == 0);Assert(mainrdata_last == (XLogRecData *) &amp;mainrdata_head);Assert(mainrdata_len == 0);if (!XLogInsertAllowed()) elog(ERROR, &quot;cannot make new WAL entries during recovery&quot;);if (begininsert_called) elog(ERROR, &quot;XLogBeginInsert was already called&quot;);begininsert_called = true; XLogRegisterData 将本条wal记录的特殊结构体数据注册到wal记录，比如XLOG_HEAP_INSERT子类型的xl_heap_insert结构体。 将一些旧元组数据注册到wal记录，比如执行update语句的旧元组数据、delete语句的旧元组数据。 12345678910111213141516// 检查是否已经开始构造WALAssert(begininsert_called);// 检查数据量是否超过限制值if (num_rdatas &gt;= max_rdatas) elog(ERROR, &quot;too much WAL data&quot;);rdata = &amp;rdatas[num_rdatas++];rdata-&gt;data = data;rdata-&gt;len = len;// 使用 mainrdata_last 指针跟踪链条的结束点,在这里不需要清除next变量mainrdata_last-&gt;next = rdata;mainrdata_last = rdata;mainrdata_len += len; XLogRegisterBuffer 将涉及到的buff注册到wal记录，比如insert语句的目标buff、update语句的目标buff和源buff 12345678910111213141516171819// 找到registered_buffer数组中第一个空的的位置if (block_id &gt;= max_registered_block_id)&#123; if (block_id &gt;= max_registered_buffers) elog(ERROR, &quot;too many registered buffers&quot;); max_registered_block_id = block_id + 1;&#125;// 将这个buffer的数据填充regbuf = &amp;registered_buffers[block_id];BufferGetTag(buffer, &amp;regbuf-&gt;rnode, &amp;regbuf-&gt;forkno, &amp;regbuf-&gt;block);regbuf-&gt;page = BufferGetPage(buffer);regbuf-&gt;flags = flags;regbuf-&gt;rdata_tail = (XLogRecData *) &amp;regbuf-&gt;rdata_head;regbuf-&gt;rdata_len = 0;// 将缓冲区标记为已使用regbuf-&gt;in_use = true; XLogRegisterBufData 函数主要作用是将元组内容注册到WAL记录中。需要参数block id，这个id必须是已经通过XLogRegisterBuffer注册的block 1234567891011121314151617// 读取已经注册的缓冲区结构regbuf = &amp;registered_buffers[block_id];if (!regbuf-&gt;in_use) elog(ERROR, &quot;no block with id %d registered with WAL insertion&quot;, block_id);// 读取buffer数据if (num_rdatas &gt;= max_rdatas) elog(ERROR, &quot;too much WAL data&quot;);rdata = &amp;rdatas[num_rdatas++];rdata-&gt;data = data;rdata-&gt;len = len;regbuf-&gt;rdata_tail-&gt;next = rdata;regbuf-&gt;rdata_tail = rdata;regbuf-&gt;rdata_len += len; XLogInsert 插入WAL的操作由函数XLogInsert完成，根据Rdata链表和相应的资源管理器info向WAL日志文件中插入一条WAL记录。事务执行插入，删除，更新，提交，终止或回滚命令时都需要调用此函数 判断调用时是否设置了rmgr标记位： 1234if ((info &amp; ~(XLR_RMGR_INFO_MASK | XLR_SPECIAL_REL_UPDATE | XLR_CHECK_CONSISTENCY)) != 0) elog(PANIC, &quot;invalid xlog info mask %02X&quot;, info); 如果处于bootstrap模式，除了XLog资源外，不需要实际记录内容，指向第一个检查点的指针 123456if (IsBootstrapProcessingMode() &amp;&amp; rmid != RM_XLog_ID)&#123; XLogResetInsertion(); EndPos = SizeOfXLogLongPHD; return EndPos;&#125; 组合成完整的WAL记录并写入WAL日志 12345678910111213141516do&#123; XLogRecPtr RedoRecPtr; bool doPageWrites; XLogRecPtr fpw_lsn; XLogRecData *rdt; GetFullPageWriteInfo(&amp;RedoRecPtr, &amp;doPageWrites); // 调用函数组装注册的数据 rdt = XLogRecordAssemble(rmid, info, RedoRecPtr, doPageWrites, &amp;fpw_lsn); // 将组装好的数据写入到WAL内存中 EndPos = XLogInsertRecord(rdt, fpw_lsn, curinsert_flags);&#125; while (EndPos == InvalidXLogRecPtr); XLogRecordAssemble 函数用于将已注册的数据和缓冲区页面数据组装成一条WAL记录，将其写入到XLogRecData链表中。 执行到这个阶段，wal记录的数据存储在： mainrdata_head 每一个注册的buff的rdata_head 每一个注册的buff的page字段中 函数执行过程如下： 保存头部信息 123456789101112131415XLogRecData *rdt; // XLogRecData链表指针uint32 total_len = 0;int block_id;pg_crc32c rdata_crc;registered_buffer *prev_regbuf = NULL;XLogRecData *rdt_datas_last;XLogRecord *rechdr;char *scratch = hdr_scratch;rechdr = (XLogRecord *) scratch;scratch += SizeOfXLogRecord;hdr_rdt.next = NULL;rdt_datas_last = &amp;hdr_rdt;hdr_rdt.data = hdr_scratch; 构造保存所有块公用的数据部分的rdata链 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166*fpw_lsn = InvalidXLogRecPtr;for (block_id = 0; block_id &lt; max_registered_block_id; block_id++)&#123; registered_buffer *regbuf = &amp;registered_buffers[block_id]; XLogRecordBlockHeader bkpb; XLogRecordBlockImageHeader bimg; XLogRecordBlockCompressHeader cbimg = &#123;0&#125;; bool samerel; bool is_compressed = false; bool include_image; // 设置block头部信息 bkpb.id = block_id; bkpb.fork_flags = regbuf-&gt;forkno; bkpb.data_length = 0; // 设置标记位 if ((regbuf-&gt;flags &amp; REGBUF_WILL_INIT) == REGBUF_WILL_INIT) bkpb.fork_flags |= BKPBLOCK_WILL_INIT; // 执行full_page_write，写入XLogRecordBlockImageHeader if (include_image) &#123; Page page = regbuf-&gt;page; // 获取对应的page uint16 compressed_len = 0; // 压缩后的大小 // page需要备份，计算空闲空间大小和偏移 // &quot;hole&quot;指的是page中的空白区域 if (regbuf-&gt;flags &amp; REGBUF_STANDARD) &#123; // 如果页面遵循标准布局，lower和upper指针将被跳过 uint16 lower = ((PageHeader) page)-&gt;pd_lower; // 获取lower uint16 upper = ((PageHeader) page)-&gt;pd_upper; // 获取upper // 判断page中是否存在&quot;hole&quot; if (lower &gt;= SizeOfPageHeaderData &amp;&amp; upper &gt; lower &amp;&amp; upper &lt;= BLCKSZ) &#123; // 计算“hole”的长度的偏移量 bimg.hole_offset = lower; cbimg.hole_length = upper - lower; &#125; else &#123; // 没有可以移除的&quot;hole&quot; bimg.hole_offset = 0; cbimg.hole_length = 0; &#125; &#125; else &#123; // 不是标准的页面布局，无法尝试估算&quot;hole&quot; bimg.hole_offset = 0; cbimg.hole_length = 0; &#125; // 启用WAL压缩 if (wal_compression) &#123; is_compressed = XLogCompressBackupBlock(page, bimg.hole_offset, cbimg.hole_length, regbuf-&gt;compressed_page, &amp;compressed_len); // 调用XLogCompressBackupBlock压缩 &#125; // 填充XLogRecordBlockHeader结构体的剩余字段 bkpb.fork_flags |= BKPBLOCK_HAS_IMAGE; // 为page内容构造XLogRecData入口 rdt_datas_last-&gt;next = &amp;regbuf-&gt;bkp_rdatas[0]; rdt_datas_last = rdt_datas_last-&gt;next; // 设置标记 bimg.bimg_info = (cbimg.hole_length == 0) ? 0 : BKPIMAGE_HAS_HOLE; // 在redo期间,在设置了BKPIMAGE_APPLY标记的情况下full-page才会回放. if (needs_backup) bimg.bimg_info |= BKPIMAGE_APPLY; // 需要压缩 if (is_compressed) &#123; bimg.length = compressed_len; // 压缩后的空间 bimg.bimg_info |= BKPIMAGE_IS_COMPRESSED; // 压缩标记 rdt_datas_last-&gt;data = regbuf-&gt;compressed_page; // 放在registered_buffer中 rdt_datas_last-&gt;len = compressed_len; &#125; else &#123; // 没有压缩，计算image的大小 bimg.length = BLCKSZ - cbimg.hole_length; // 如果没有&quot;hole&quot;存在 if (cbimg.hole_length == 0) &#123; rdt_datas_last-&gt;data = page; // 数据指针直接指向page rdt_datas_last-&gt;len = BLCKSZ; // 大小为block size &#125; else &#123; // 跳过hole rdt_datas_last-&gt;data = page; // 数据指针 rdt_datas_last-&gt;len = bimg.hole_offset;// 获取hole的偏移 rdt_datas_last-&gt;next = &amp;regbuf-&gt;bkp_rdatas[1];// 第2部分 rdt_datas_last = rdt_datas_last-&gt;next; rdt_datas_last-&gt;data = page + (bimg.hole_offset + cbimg.hole_length);// 指针指向第二部分 rdt_datas_last-&gt;len = BLCKSZ - (bimg.hole_offset + cbimg.hole_length);// 设置长度 &#125; &#125; total_len += bimg.length; // 调整总长度 &#125; // 如果需要包含数据 if (needs_data) &#123; // 把该缓冲区链接到调用者提供的rdata链中，构成一个整体的链表 bkpb.fork_flags |= BKPBLOCK_HAS_DATA; bkpb.data_length = regbuf-&gt;rdata_len; total_len += regbuf-&gt;rdata_len; rdt_datas_last-&gt;next = regbuf-&gt;rdata_head; rdt_datas_last = regbuf-&gt;rdata_tail; &#125; // 如果存在上一个注册的buf，而且RefFileNode相同 if (prev_regbuf &amp;&amp; RelFileNodeEquals(regbuf-&gt;rnode, prev_regbuf-&gt;rnode)) &#123; samerel = true; bkpb.fork_flags |= BKPBLOCK_SAME_REL; &#125; else samerel = false; // 切换为当前的注册的buf prev_regbuf = regbuf; // 拷贝头部信息到scratch缓冲区中 memcpy(scratch, &amp;bkpb, SizeOfXLogRecordBlockHeader); scratch += SizeOfXLogRecordBlockHeader; if (include_image) &#123; memcpy(scratch, &amp;bimg, SizeOfXLogRecordBlockImageHeader); scratch += SizeOfXLogRecordBlockImageHeader; // 压缩存储,追加SizeOfXLogRecordBlockCompressHeader if (cbimg.hole_length != 0 &amp;&amp; is_compressed) &#123; memcpy(scratch, &amp;cbimg, SizeOfXLogRecordBlockCompressHeader); scratch += SizeOfXLogRecordBlockCompressHeader; &#125; &#125; // 不是同一个REL，追加RelFileNode if (!samerel) &#123; memcpy(scratch, &amp;regbuf-&gt;rnode, sizeof(RelFileNode)); scratch += sizeof(RelFileNode); &#125; // 追加BlockNumber memcpy(scratch, &amp;regbuf-&gt;block, sizeof(BlockNumber)); scratch += sizeof(BlockNumber);&#125; 接下来组装XLog Record origin标记 1234567if ((curinsert_flags &amp; XLog_INCLUDE_ORIGIN) &amp;&amp; replorigin_session_origin != InvalidRepOriginId)&#123; *(scratch++) = (char) XLR_BLOCK_ID_ORIGIN; memcpy(scratch, &amp;replorigin_session_origin, sizeof(replorigin_session_origin)); scratch += sizeof(replorigin_session_origin);&#125; 接下来组装数据（main data） 12345678910111213141516171819202122if (mainrdata_len &gt; 0)&#123; // 长度超过255，则使用Long格式 if (mainrdata_len &gt; 255) &#123; *(scratch++) = (char) XLR_BLOCK_ID_DATA_LONG; memcpy(scratch, &amp;mainrdata_len, sizeof(uint32)); scratch += sizeof(uint32); &#125; else &#123; *(scratch++) = (char) XLR_BLOCK_ID_DATA_SHORT; *(scratch++) = (uint8) mainrdata_len; &#125; rdt_datas_last-&gt;next = mainrdata_head; rdt_datas_last = mainrdata_last; total_len += mainrdata_len;&#125;rdt_datas_last-&gt;next = NULL;hdr_rdt.len = (scratch - hdr_scratch); // 头部大小total_len += hdr_rdt.len; // 总长度 计算数据的CRC 1234INIT_CRC32C(rdata_crc);COMP_CRC32C(rdata_crc, hdr_scratch + SizeOfXLogRecord, hdr_rdt.len - SizeOfXLogRecord);for (rdt = hdr_rdt.next; rdt != NULL; rdt = rdt-&gt;next) COMP_CRC32C(rdata_crc, rdt-&gt;data, rdt-&gt;len); 最后填充记录头部信息的其他域字段 12345678rechdr-&gt;xl_xid = GetCurrentTransactionIdIfAny();rechdr-&gt;xl_tot_len = total_len;rechdr-&gt;xl_info = info;rechdr-&gt;xl_rmid = rmid;rechdr-&gt;xl_prev = InvalidXLogRecPtr;rechdr-&gt;xl_crc = rdata_crc;return &amp;hdr_rdt; XLogInsertRecord 将XLogRecordAssemble组装好的记录插入到WAL内存中。过程分两步： 在内存中为WAL记录保留足够的空间 12345678if (isLogSwitch) inserted = ReserveXLogSwitch(&amp;StartPos, &amp;EndPos, &amp;rechdr-&gt;xl_prev);else&#123; ReserveXLogInsertLocation(rechdr-&gt;xl_tot_len, &amp;StartPos, &amp;EndPos, &amp;rechdr-&gt;xl_prev); inserted = true;&#125; 将记录复制到WAL内存中 1234567891011121314151617181920if (inserted)&#123; // 计算头部的CRC rdata_crc = rechdr-&gt;xl_crc; COMP_CRC32C(rdata_crc, rechdr, offsetof(XLogRecord, xl_crc)); FIN_CRC32C(rdata_crc); rechdr-&gt;xl_crc = rdata_crc; // 所有的数据，包括header信息，均可以进行插入 CopyXLogRecordToWAL(rechdr-&gt;xl_tot_len, isLogSwitch, rdata, StartPos, EndPos); // 更新最后一条重要记录的LSN，当持有锁时，只更新第一个 if ((flags &amp; XLog_MARK_UNIMPORTANT) == 0) &#123; int lockno = holdingAllLocks ? 0 : MyLockNo; WALInsertLocks[lockno].l.lastImportantAt = StartPos; &#125;&#125; PageSetLSN 更新被修改的Page LSN","categories":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/categories/PostgreSQL/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/tags/PostgreSQL/"},{"name":"replication","slug":"replication","permalink":"https://spike1337.github.io/tags/replication/"},{"name":"WAL","slug":"WAL","permalink":"https://spike1337.github.io/tags/WAL/"}]}],"categories":[{"name":"demo","slug":"demo","permalink":"https://spike1337.github.io/categories/demo/"},{"name":"Linux","slug":"Linux","permalink":"https://spike1337.github.io/categories/Linux/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/categories/PostgreSQL/"}],"tags":[{"name":"demo","slug":"demo","permalink":"https://spike1337.github.io/tags/demo/"},{"name":"Linux","slug":"Linux","permalink":"https://spike1337.github.io/tags/Linux/"},{"name":"libc","slug":"libc","permalink":"https://spike1337.github.io/tags/libc/"},{"name":"file access","slug":"file-access","permalink":"https://spike1337.github.io/tags/file-access/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://spike1337.github.io/tags/PostgreSQL/"},{"name":"storage","slug":"storage","permalink":"https://spike1337.github.io/tags/storage/"},{"name":"tools","slug":"tools","permalink":"https://spike1337.github.io/tags/tools/"},{"name":"transaction","slug":"transaction","permalink":"https://spike1337.github.io/tags/transaction/"},{"name":"MVCC","slug":"MVCC","permalink":"https://spike1337.github.io/tags/MVCC/"},{"name":"replication","slug":"replication","permalink":"https://spike1337.github.io/tags/replication/"},{"name":"WAL","slug":"WAL","permalink":"https://spike1337.github.io/tags/WAL/"}]}